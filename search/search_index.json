{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 Conductor is a cloud platform product that uses the massive resources of multiple cloud providers to grow and shrink your studio\u2019s available computing power on demand.","title":"Home"},{"location":"#overview","text":"Conductor is a cloud platform product that uses the massive resources of multiple cloud providers to grow and shrink your studio\u2019s available computing power on demand.","title":"Overview"},{"location":"meta/","text":"Docs on docs \u00b6 This docs project contains technical documentation for public facing Conductor components. Internal docs are beyond scope. Setup \u00b6 Clone the repository git clone git@github.com:AtomicConductor/AtomicConductor.github.io.git cd AtomicConductor.github.io git checkout authoring This documentation is built on mkdocs . You'll also need to install the Windmill theme, and some code formatting plugins. pip install mkdocs mkdocs-windmill pygments markdown-fenced-code-tabs You'll find a mkdocs.yml file and a docs folder in the root of the repo. The site folder is autogenerated so don't edit. To start the server locally enter: mkdocs serve You can view the site locally at http://127.0.0.1:8000 Publish \u00b6 Once you've made some edits, you can commit to the authoring branch and publish to the Conductor documentation site. mkdocs gh-deploy That builds and pushes the site to the master branch at Github. You can view it at https://atomicconductor.github.io/ Warning Don't merge or commit to master . It will get overwritten. Write docs \u00b6 Note Many items below are rough thoughts and placeholders. Its all up for discussion. Grammar & Style \u00b6 Follow the Google developer documentation style guide . List other guidelines here: Don't try to sell the benefits, this isn't marcom. Omit needless words. -- Steve Krug Scan the doc. Can you make a mental index? Check out David Ogilvy's writing tips Avoid using the present participle. Don't use the present participle. Don't put a period after headings. Use a grammar checker. Glossary \u00b6 Try to be consistent with Conductor concepts. For example, which of these? disks | storage | file-system first-middle-last | FML | scout frames input data | scene data | project data non-preemptible | standard | premium preemptible | low-cost render cores | cores render machine | render instance | render VM | render node Core V2.1 What to document. \u00b6 Most documentation can be split into: Get started: Help the user get a result as fast as possible. Reference: Node referenece, API reference. Concept discussion: e.g. How to choose an instance type to minimize costs. The doc site doesn't eliminate the need for contextual documentation like tooltips etc. Don't document: Obvious features. Things any normal computer user should know. Things unrelated to Conductor. e.g. Docker. Provide links if necessary. Try to improve UX to obviate the need for documentation. Responsibilities \u00b6 The dev who writes code is responsible for its documention. Code reviewers should check the docs reflect the changes. Build and Deploy (future thoughts) \u00b6 Consider these constraints: Documentation lives alongside the code it refers to. Public facing code lives in at least 2 repositories. The documentation site should be built as one site. Publish should be automatic. Keep it simple. There are 2 conventional ways to build with Github pages: Project Pages . Docs are in the same repo as the code. User and Organization Pages . The docs live in their own repo. How do we resolve this? Formatting examples \u00b6 Images \u00b6 Code hilighting and fenced tabs \u00b6 This is the autumn css theme for pygments. There are plenty of others. Fencing is achieved by making a series of uninterrupted blocks of code. Python \"\"\"Provide UI to specify what events to notify users of. Currently only email notifications. \"\"\" import re import ix # Simple loose email regex, matches 1 email address. SIMPLE_EMAIL_RE = re . compile ( r \"^\\S+@\\S+$\" ) def handle_email_addresses ( obj , _ ): \"\"\"Validate email addresses when attribute changes.\"\"\" val = obj . get_attribute ( \"email_addresses\" ) . get_string () . strip ( ',' ) . strip () result = bool ( val ) for address in [ x . strip () for x in val . split ( ',' )]: if not SIMPLE_EMAIL_RE . match ( address ): result = False break if not result : ix . log_warning ( \"Email addresses are invalid.\" ) Bash #export MAYA_DEBUG_ENABLE_CRASH_REPORTING=1 export MAYA_APP_DIR = $HOME /maya export MAYA_VERSION = \"2018\" export MAYA_MODULE_PATH = ${ MAYA_MODULE_PATH } : ${ MAYA_APP_DIR } /modules # maya functions ######################################### function curr_maya_project () { local maya_prj_list = ` cat \" ${ MAYA_APP_DIR } / ${ MAYA_VERSION } /prefs/userPrefs.mel\" | grep RecentProjectsList | sed \"s/\\\"//g\" ` local curr_maya_prj = ` echo $maya_prj_list | awk '{print $NF}' ` echo $curr_maya_prj } alias mp = 'cd `curr_maya_project`' alias llrm = 'echo \"Paste ls -l output for files to delete. ^D when done\"; \\rm -rf `awk ' \\' '{print $9}' \\' '`' # remove by pasting from long list output Json { \"autoretry_policy\" : { \"preempted\" : { \"max_retries\" : 3 } }, \"max_instances\" : 0 , \"notify\" : null , \"output_path\" : \"/Users/julian/projects/fish/clarisse_fish/images/jobA\" , \"upload_paths\" : [ \"/Users/julian/projects/fish/clarisse_fish/arch_shading.project\" , \"/Users/julian/projects/fish/maya_fish/cache/alembic/fish_100.abc\" ] } Docker FROM gcr.io/eloquent-vector-104019/conductor_docker_base:7abb26b9-3bf2-4927-846f-ed15460046ea RUN apt-get update && apt-get install -y bzip2 # RUN echo \"deb http://http.debian.net/debian/ jessie main\" > /etc/apt/sources.list && \\ WORKDIR /work ADD ./silhouettev7_Silhouette-v7.0.11.tgz ./ COPY ./install.py ./ RUN python install.py ENV PATH /opt/silhouette7.0.11: $PATH Tables \u00b6 Release label Operating system Download link Stable Centos el7 installer conductor-v2.7.100-0.el7.x86_64.rpm Stable Windows 10 installer conductor-v2.7.100.exe Stable Mac installer conductor-v2.7.100.pkg Stable Manual install v2.7.100.tar.gz Clarisse beta Centos el7 installer conductor-v2.8.5-0.el7.x86_64.rpm Clarisse beta Windows 10 installer conductor-v2.8.5.exe Clarisse beta Mac installer conductor-v2.8.5.pkg Clarisse beta Manual install v2.8.5.tar.gz All conductor-client releases All Github releases page Notes and special panels \u00b6 Note You can hover over any attribute name to get a detailed description of its purpose and behavior. Warning Don't go out in this town after 9:30pm. Danger You are likely to cause considerable damage if you touch this button. Misc \u00b6 For strikethrough, use <del>word</del> or <s>word</s> as tildes dont work.","title":"Meta"},{"location":"meta/#docs-on-docs","text":"This docs project contains technical documentation for public facing Conductor components. Internal docs are beyond scope.","title":"Docs on docs"},{"location":"meta/#setup","text":"Clone the repository git clone git@github.com:AtomicConductor/AtomicConductor.github.io.git cd AtomicConductor.github.io git checkout authoring This documentation is built on mkdocs . You'll also need to install the Windmill theme, and some code formatting plugins. pip install mkdocs mkdocs-windmill pygments markdown-fenced-code-tabs You'll find a mkdocs.yml file and a docs folder in the root of the repo. The site folder is autogenerated so don't edit. To start the server locally enter: mkdocs serve You can view the site locally at http://127.0.0.1:8000","title":"Setup"},{"location":"meta/#publish","text":"Once you've made some edits, you can commit to the authoring branch and publish to the Conductor documentation site. mkdocs gh-deploy That builds and pushes the site to the master branch at Github. You can view it at https://atomicconductor.github.io/ Warning Don't merge or commit to master . It will get overwritten.","title":"Publish"},{"location":"meta/#write-docs","text":"Note Many items below are rough thoughts and placeholders. Its all up for discussion.","title":"Write docs"},{"location":"meta/#grammar-style","text":"Follow the Google developer documentation style guide . List other guidelines here: Don't try to sell the benefits, this isn't marcom. Omit needless words. -- Steve Krug Scan the doc. Can you make a mental index? Check out David Ogilvy's writing tips Avoid using the present participle. Don't use the present participle. Don't put a period after headings. Use a grammar checker.","title":"Grammar &amp; Style"},{"location":"meta/#glossary","text":"Try to be consistent with Conductor concepts. For example, which of these? disks | storage | file-system first-middle-last | FML | scout frames input data | scene data | project data non-preemptible | standard | premium preemptible | low-cost render cores | cores render machine | render instance | render VM | render node Core V2.1","title":"Glossary"},{"location":"meta/#what-to-document","text":"Most documentation can be split into: Get started: Help the user get a result as fast as possible. Reference: Node referenece, API reference. Concept discussion: e.g. How to choose an instance type to minimize costs. The doc site doesn't eliminate the need for contextual documentation like tooltips etc. Don't document: Obvious features. Things any normal computer user should know. Things unrelated to Conductor. e.g. Docker. Provide links if necessary. Try to improve UX to obviate the need for documentation.","title":"What to document."},{"location":"meta/#responsibilities","text":"The dev who writes code is responsible for its documention. Code reviewers should check the docs reflect the changes.","title":"Responsibilities"},{"location":"meta/#build-and-deploy-future-thoughts","text":"Consider these constraints: Documentation lives alongside the code it refers to. Public facing code lives in at least 2 repositories. The documentation site should be built as one site. Publish should be automatic. Keep it simple. There are 2 conventional ways to build with Github pages: Project Pages . Docs are in the same repo as the code. User and Organization Pages . The docs live in their own repo. How do we resolve this?","title":"Build and Deploy (future thoughts)"},{"location":"meta/#formatting-examples","text":"","title":"Formatting examples"},{"location":"meta/#images","text":"","title":"Images"},{"location":"meta/#code-hilighting-and-fenced-tabs","text":"This is the autumn css theme for pygments. There are plenty of others. Fencing is achieved by making a series of uninterrupted blocks of code. Python \"\"\"Provide UI to specify what events to notify users of. Currently only email notifications. \"\"\" import re import ix # Simple loose email regex, matches 1 email address. SIMPLE_EMAIL_RE = re . compile ( r \"^\\S+@\\S+$\" ) def handle_email_addresses ( obj , _ ): \"\"\"Validate email addresses when attribute changes.\"\"\" val = obj . get_attribute ( \"email_addresses\" ) . get_string () . strip ( ',' ) . strip () result = bool ( val ) for address in [ x . strip () for x in val . split ( ',' )]: if not SIMPLE_EMAIL_RE . match ( address ): result = False break if not result : ix . log_warning ( \"Email addresses are invalid.\" ) Bash #export MAYA_DEBUG_ENABLE_CRASH_REPORTING=1 export MAYA_APP_DIR = $HOME /maya export MAYA_VERSION = \"2018\" export MAYA_MODULE_PATH = ${ MAYA_MODULE_PATH } : ${ MAYA_APP_DIR } /modules # maya functions ######################################### function curr_maya_project () { local maya_prj_list = ` cat \" ${ MAYA_APP_DIR } / ${ MAYA_VERSION } /prefs/userPrefs.mel\" | grep RecentProjectsList | sed \"s/\\\"//g\" ` local curr_maya_prj = ` echo $maya_prj_list | awk '{print $NF}' ` echo $curr_maya_prj } alias mp = 'cd `curr_maya_project`' alias llrm = 'echo \"Paste ls -l output for files to delete. ^D when done\"; \\rm -rf `awk ' \\' '{print $9}' \\' '`' # remove by pasting from long list output Json { \"autoretry_policy\" : { \"preempted\" : { \"max_retries\" : 3 } }, \"max_instances\" : 0 , \"notify\" : null , \"output_path\" : \"/Users/julian/projects/fish/clarisse_fish/images/jobA\" , \"upload_paths\" : [ \"/Users/julian/projects/fish/clarisse_fish/arch_shading.project\" , \"/Users/julian/projects/fish/maya_fish/cache/alembic/fish_100.abc\" ] } Docker FROM gcr.io/eloquent-vector-104019/conductor_docker_base:7abb26b9-3bf2-4927-846f-ed15460046ea RUN apt-get update && apt-get install -y bzip2 # RUN echo \"deb http://http.debian.net/debian/ jessie main\" > /etc/apt/sources.list && \\ WORKDIR /work ADD ./silhouettev7_Silhouette-v7.0.11.tgz ./ COPY ./install.py ./ RUN python install.py ENV PATH /opt/silhouette7.0.11: $PATH","title":"Code hilighting and fenced tabs"},{"location":"meta/#tables","text":"Release label Operating system Download link Stable Centos el7 installer conductor-v2.7.100-0.el7.x86_64.rpm Stable Windows 10 installer conductor-v2.7.100.exe Stable Mac installer conductor-v2.7.100.pkg Stable Manual install v2.7.100.tar.gz Clarisse beta Centos el7 installer conductor-v2.8.5-0.el7.x86_64.rpm Clarisse beta Windows 10 installer conductor-v2.8.5.exe Clarisse beta Mac installer conductor-v2.8.5.pkg Clarisse beta Manual install v2.8.5.tar.gz All conductor-client releases All Github releases page","title":"Tables"},{"location":"meta/#notes-and-special-panels","text":"Note You can hover over any attribute name to get a detailed description of its purpose and behavior. Warning Don't go out in this town after 9:30pm. Danger You are likely to cause considerable damage if you touch this button.","title":"Notes and special panels"},{"location":"meta/#misc","text":"For strikethrough, use <del>word</del> or <s>word</s> as tildes dont work.","title":"Misc"},{"location":"client_tools/commandline/","text":"Command line submission \u00b6 Introduction \u00b6 The Conductor client tools provide modules and classes to help you craft a submission in cases where a GUI submitter is not suitable. Installation \u00b6 If you haven't already done so, install Conductor client tools . Quick start \u00b6 The Python code below demonstrates how to use the Submit class to create a command line job submission. import logging from conductor.lib import conductor_submit , package_utils , api_client # Set up logging (optional) conductor_submit . set_logging ( logging . DEBUG ) # Create a dictionary of arguments for your job. args = {} # Give the job a title to help identify it in the web dashboard. args [ \"job_title\" ] = \"Test Job: Vray Standalone Test\" # Specify the Conductor project to associate this job with. args [ \"project\" ] = \"default\" # Specify the what type of instance to use. args [ \"machine_flavor\" ] = \"standard\" args [ \"cores\" ] = 2 # Specify the list of file dependencies the job requires. # This includes textures, caches, plugins, tools. # You may add files or directories from anywhere on your filesystem. args [ \"upload_paths\" ] = [ \"/path/to/project/batman_0008.vrscene\" , \"/path/to/project/batman_0024.vrscene\" , \"/path/to/tools/custom_vray\" ] # Indicate that uploading should occur immediately. If this option is `False`, # it indicates that uploading will be handled by the Conductor uploader daemon. args [ \"local_upload\" ] = True # If your job uses custom tools or plugins, you'll need to provide the necessary # environment so they can be found. custom_environment = { \"VRAY_PLUGINS_x64\" : \"/path/to/tools/custom_vray/plugin\" , \"LD_LIBRARY_PATH\" : \"/path/to/tools/custom_vray/bin\" } # Indicate which software packages should be made available for the job # See the notes below for help on finding package IDs for each required # software package. args [ \"software_package_ids\" ] = [ \"7208372e306614d514944938c395e0e7\" ] # Request the packages that you want to use from Conductor. all_packages = api_client . request_software_packages () packages = [ p for p in all_packages if p [ \"package_id\" ] in args [ \"software_package_ids\" ]] # Merge the environments from your chosen packages with the custom environment. args [ \"environment\" ] = package_utils . merge_package_environments ( packages , base_env = custom_environment ) # Define the task data for the job. # Each Task entry defines a command to be excecuted. args [ \"tasks_data\" ] = [ { \"command\" : \"vray -display=0 -sceneFile=/path/to/project/batman_0008.vrscene -imgFile=/path/to/project/output/output.exr\" , \"frames\" : \"8\" }, { \"command\" : \"vray -display=0 -sceneFile=/path/to/project/batman_0024.vrscene -imgFile=/path/to/project/output/output.exr\" , \"frames\" : \"24\" } ] # Define the directory where rendered images can be found when tasks are complete. args [ \"output_path\" ] = \"/path/to/project/output\" # Instantiate a Submit object with the job args. submission = conductor_submit . Submit ( args ) # Run the submission response , response_code = submission . main () # Inspect the response code print response_code # 201 # Inspect the response print response # {u'body': u'job submitted.', # u'jobid': u'00695', # u'status': u'success', # u'uri': u'/jobs/00695'} Package Ids \u00b6 Use the Python code below to find package_id s for the packages you require. from conductor.lib import api_client packages = api_client . request_software_packages () packages = sorted ( packages , key = lambda x : x [ \"relative_path\" ]) print \" \\n \" . join ([ \"{} -- {}\" . format ( p [ \"package_id\" ], p [ \"relative_path\" ]) for p in packages ]) Reference \u00b6 The list below describes all available submission arguments. autoretry_policy \u00b6 Dictates auto-retry behavior for unsuccessful tasks. This is particularly useful for preemptible instances. \"autoretry_policy\" : { \"preempted\" : { \"max_retries\" : 2 }, # when a task is preempted \"failed\" : { \"max_retries\" : 1 } # when a task fails } chunk_size \u00b6 The number of frames to render per task. \"chunk_size\" : 15 cores \u00b6 The number of cpu cores the instance will have (2 minimum for highmem and highcpu instance types) \"cores\" : 64 enforced_md5s \u00b6 Only relevant when using the uploader daemon. Dictates md5 hash values that specific files must adhere to upon uploading via the uploader daemon. This is a mechanism to ensure that a file has not been modified between the time the job was submitted and the time the uploader daemon started to upload. { \"/tmp/my_maya_file.ma\" : \"GDVem8GYRUuh4douZwIwFg==\" } environment \u00b6 Specifies environment variables to be set om the render machine. { \"PYTHONPATH\" : \"/tmp/site-packages:/tmp/pipeline/site-packages\" } job_title \u00b6 The title displayed in the web dashboard. \"title\" : \"My maya job\" local_upload \u00b6 Dictates whether the submission will upload the job's dependencies immediately (True) or queue them for an uploader daemon to handle (False). \"local_upload\" : False location \u00b6 A string that indicates which location the job should be associated with. This option is relevant if you submit jobs from different locations. These could be differing geographic locations or simply machines that have differing file system views. Typically each location should have its own Conductor downloader and uploader daemons running. The location feature allows each daemon to target only jobs that match its corresponding location. \"location\" : \"mars\" machine_flavor \u00b6 The instance type to use for the job. This works together with the cores argument. Valid options are: standard highcpu highmem \"machine_flavor\" : \"highcpu\" metadata \u00b6 Add custom metadata data to the job submission to help filter usage reports and so on. \"metadata\" : { \"shot\" : \"Ez500\" , \"asset\" : \"apple\" } notify \u00b6 Emails addresses to be notified when the job is complete. \"notify\" : [ \"fred@flintstones.com\" , \"wilma@flintstones.com\" ] output_path \u00b6 The directory where images and other output files are written. This is also the location on the local filesystem where files will be downloaded to. \"output_path\" : \"/tmp/render_output\" preemptible \u00b6 Whether the job uses preemptible instances. \"preemptible\" : True priority \u00b6 Specify whether this job should take preference over other jobs in your account. \"priority\" : 800 project \u00b6 The name of the Conductor project to associate this job with. \"project\" : \"Spiderman\" scout_frame \u00b6 Tasks that contain scout frames are run immediately, while the rest are put on hold. \"scout_frame\" : \"1-100x5\" software_package_ids \u00b6 Ids for software packages to use for the job. Packages are identified by their ID number, which can be queried from Conductor's rest api. \"software_package_ids\" : [ \"ae8026b7d9cfe524a77a3ebe94b9130a\" , \"7208372e306614d514944938c395e0e7\" ] tasks_data \u00b6 The definition of tasks. Each task dictionary must contain a command to be executed. It may optionally contain a frames field, which helps to determine whether it is a scout-frame. \"tasks_data\" : [ { \"command\" : \"vray -display=0 -sceneFile=/tmp/batman_0008.vrscene\" , \"frames\" : \"8\" }, { \"command\" : \"vray -display=0 -sceneFile=/tmp/batman_0024.vrscene\" , \"frames\" : \"24\" } ] upload_paths \u00b6 A list of files and directories to be uploaded. \"upload_paths\" : [ \"/tmp/sourceimages\" , \"/tmp/my_maya_file.ma\" ]","title":"Command Line"},{"location":"client_tools/commandline/#command-line-submission","text":"","title":"Command line submission"},{"location":"client_tools/commandline/#introduction","text":"The Conductor client tools provide modules and classes to help you craft a submission in cases where a GUI submitter is not suitable.","title":"Introduction"},{"location":"client_tools/commandline/#installation","text":"If you haven't already done so, install Conductor client tools .","title":"Installation"},{"location":"client_tools/commandline/#quick-start","text":"The Python code below demonstrates how to use the Submit class to create a command line job submission. import logging from conductor.lib import conductor_submit , package_utils , api_client # Set up logging (optional) conductor_submit . set_logging ( logging . DEBUG ) # Create a dictionary of arguments for your job. args = {} # Give the job a title to help identify it in the web dashboard. args [ \"job_title\" ] = \"Test Job: Vray Standalone Test\" # Specify the Conductor project to associate this job with. args [ \"project\" ] = \"default\" # Specify the what type of instance to use. args [ \"machine_flavor\" ] = \"standard\" args [ \"cores\" ] = 2 # Specify the list of file dependencies the job requires. # This includes textures, caches, plugins, tools. # You may add files or directories from anywhere on your filesystem. args [ \"upload_paths\" ] = [ \"/path/to/project/batman_0008.vrscene\" , \"/path/to/project/batman_0024.vrscene\" , \"/path/to/tools/custom_vray\" ] # Indicate that uploading should occur immediately. If this option is `False`, # it indicates that uploading will be handled by the Conductor uploader daemon. args [ \"local_upload\" ] = True # If your job uses custom tools or plugins, you'll need to provide the necessary # environment so they can be found. custom_environment = { \"VRAY_PLUGINS_x64\" : \"/path/to/tools/custom_vray/plugin\" , \"LD_LIBRARY_PATH\" : \"/path/to/tools/custom_vray/bin\" } # Indicate which software packages should be made available for the job # See the notes below for help on finding package IDs for each required # software package. args [ \"software_package_ids\" ] = [ \"7208372e306614d514944938c395e0e7\" ] # Request the packages that you want to use from Conductor. all_packages = api_client . request_software_packages () packages = [ p for p in all_packages if p [ \"package_id\" ] in args [ \"software_package_ids\" ]] # Merge the environments from your chosen packages with the custom environment. args [ \"environment\" ] = package_utils . merge_package_environments ( packages , base_env = custom_environment ) # Define the task data for the job. # Each Task entry defines a command to be excecuted. args [ \"tasks_data\" ] = [ { \"command\" : \"vray -display=0 -sceneFile=/path/to/project/batman_0008.vrscene -imgFile=/path/to/project/output/output.exr\" , \"frames\" : \"8\" }, { \"command\" : \"vray -display=0 -sceneFile=/path/to/project/batman_0024.vrscene -imgFile=/path/to/project/output/output.exr\" , \"frames\" : \"24\" } ] # Define the directory where rendered images can be found when tasks are complete. args [ \"output_path\" ] = \"/path/to/project/output\" # Instantiate a Submit object with the job args. submission = conductor_submit . Submit ( args ) # Run the submission response , response_code = submission . main () # Inspect the response code print response_code # 201 # Inspect the response print response # {u'body': u'job submitted.', # u'jobid': u'00695', # u'status': u'success', # u'uri': u'/jobs/00695'}","title":"Quick start"},{"location":"client_tools/commandline/#package-ids","text":"Use the Python code below to find package_id s for the packages you require. from conductor.lib import api_client packages = api_client . request_software_packages () packages = sorted ( packages , key = lambda x : x [ \"relative_path\" ]) print \" \\n \" . join ([ \"{} -- {}\" . format ( p [ \"package_id\" ], p [ \"relative_path\" ]) for p in packages ])","title":"Package Ids"},{"location":"client_tools/commandline/#reference","text":"The list below describes all available submission arguments.","title":"Reference"},{"location":"client_tools/commandline/#autoretry_policy","text":"Dictates auto-retry behavior for unsuccessful tasks. This is particularly useful for preemptible instances. \"autoretry_policy\" : { \"preempted\" : { \"max_retries\" : 2 }, # when a task is preempted \"failed\" : { \"max_retries\" : 1 } # when a task fails }","title":"autoretry_policy"},{"location":"client_tools/commandline/#chunk_size","text":"The number of frames to render per task. \"chunk_size\" : 15","title":"chunk_size"},{"location":"client_tools/commandline/#cores","text":"The number of cpu cores the instance will have (2 minimum for highmem and highcpu instance types) \"cores\" : 64","title":"cores"},{"location":"client_tools/commandline/#enforced_md5s","text":"Only relevant when using the uploader daemon. Dictates md5 hash values that specific files must adhere to upon uploading via the uploader daemon. This is a mechanism to ensure that a file has not been modified between the time the job was submitted and the time the uploader daemon started to upload. { \"/tmp/my_maya_file.ma\" : \"GDVem8GYRUuh4douZwIwFg==\" }","title":"enforced_md5s"},{"location":"client_tools/commandline/#environment","text":"Specifies environment variables to be set om the render machine. { \"PYTHONPATH\" : \"/tmp/site-packages:/tmp/pipeline/site-packages\" }","title":"environment"},{"location":"client_tools/commandline/#job_title","text":"The title displayed in the web dashboard. \"title\" : \"My maya job\"","title":"job_title"},{"location":"client_tools/commandline/#local_upload","text":"Dictates whether the submission will upload the job's dependencies immediately (True) or queue them for an uploader daemon to handle (False). \"local_upload\" : False","title":"local_upload"},{"location":"client_tools/commandline/#location","text":"A string that indicates which location the job should be associated with. This option is relevant if you submit jobs from different locations. These could be differing geographic locations or simply machines that have differing file system views. Typically each location should have its own Conductor downloader and uploader daemons running. The location feature allows each daemon to target only jobs that match its corresponding location. \"location\" : \"mars\"","title":"location"},{"location":"client_tools/commandline/#machine_flavor","text":"The instance type to use for the job. This works together with the cores argument. Valid options are: standard highcpu highmem \"machine_flavor\" : \"highcpu\"","title":"machine_flavor"},{"location":"client_tools/commandline/#metadata","text":"Add custom metadata data to the job submission to help filter usage reports and so on. \"metadata\" : { \"shot\" : \"Ez500\" , \"asset\" : \"apple\" }","title":"metadata"},{"location":"client_tools/commandline/#notify","text":"Emails addresses to be notified when the job is complete. \"notify\" : [ \"fred@flintstones.com\" , \"wilma@flintstones.com\" ]","title":"notify"},{"location":"client_tools/commandline/#output_path","text":"The directory where images and other output files are written. This is also the location on the local filesystem where files will be downloaded to. \"output_path\" : \"/tmp/render_output\"","title":"output_path"},{"location":"client_tools/commandline/#preemptible","text":"Whether the job uses preemptible instances. \"preemptible\" : True","title":"preemptible"},{"location":"client_tools/commandline/#priority","text":"Specify whether this job should take preference over other jobs in your account. \"priority\" : 800","title":"priority"},{"location":"client_tools/commandline/#project","text":"The name of the Conductor project to associate this job with. \"project\" : \"Spiderman\"","title":"project"},{"location":"client_tools/commandline/#scout_frame","text":"Tasks that contain scout frames are run immediately, while the rest are put on hold. \"scout_frame\" : \"1-100x5\"","title":"scout_frame"},{"location":"client_tools/commandline/#software_package_ids","text":"Ids for software packages to use for the job. Packages are identified by their ID number, which can be queried from Conductor's rest api. \"software_package_ids\" : [ \"ae8026b7d9cfe524a77a3ebe94b9130a\" , \"7208372e306614d514944938c395e0e7\" ]","title":"software_package_ids"},{"location":"client_tools/commandline/#tasks_data","text":"The definition of tasks. Each task dictionary must contain a command to be executed. It may optionally contain a frames field, which helps to determine whether it is a scout-frame. \"tasks_data\" : [ { \"command\" : \"vray -display=0 -sceneFile=/tmp/batman_0008.vrscene\" , \"frames\" : \"8\" }, { \"command\" : \"vray -display=0 -sceneFile=/tmp/batman_0024.vrscene\" , \"frames\" : \"24\" } ]","title":"tasks_data"},{"location":"client_tools/commandline/#upload_paths","text":"A list of files and directories to be uploaded. \"upload_paths\" : [ \"/tmp/sourceimages\" , \"/tmp/my_maya_file.ma\" ]","title":"upload_paths"},{"location":"client_tools/config_yml/","text":"Configuration file \u00b6 Introduction \u00b6 Conductor client tools rely upon a configuration file named config.yml . The default location for this file varies by platform: Mac ~/Library/Application Support/Conductor/config.yml Linux ~/.conductor/config.yml Windows C:\\Users\\<you>\\AppData\\Roaming\\Conductor Technologies\\Conductor\\config.yml Keys \u00b6 The available settings are specified with YAML keys as described below. environment \u00b6 Additional environment variable assignments to be included in submissions. For example, you may want to upload and run a pre-render script. You can use this key to add the path to the script. environment : PATH : /path/to/my/scripts output_dir \u00b6 By default, files are downloaded to the directory that was specified on submission. Use this key to override that directory and download to the specified location. output_dir : /special/path/to/my/renders upload_paths \u00b6 A list of additional paths to be uploaded. Both files and directories are valid. upload_paths : - /path/to/my/scripts/prerender.py - /assets/not/detected/during/dependency/scan/ local_upload \u00b6 Specify whether uploads should run on the workstation where jobs are submitted. Set this key to False if you have a dedicated machine to run an uploader daemon. local_upload : False api_key_path \u00b6 Full path to the location of a file containing your API_KEY. This is optional if you are not running an uploader or downloader daemons. api_key_path : /path/to/my/conductor_api_key.json location \u00b6 Tag your submissions with a location. This allows you to download only those tagged jobs while running the downloader daemon. location : london_studio","title":"Configuration File"},{"location":"client_tools/config_yml/#configuration-file","text":"","title":"Configuration file"},{"location":"client_tools/config_yml/#introduction","text":"Conductor client tools rely upon a configuration file named config.yml . The default location for this file varies by platform: Mac ~/Library/Application Support/Conductor/config.yml Linux ~/.conductor/config.yml Windows C:\\Users\\<you>\\AppData\\Roaming\\Conductor Technologies\\Conductor\\config.yml","title":"Introduction"},{"location":"client_tools/config_yml/#keys","text":"The available settings are specified with YAML keys as described below.","title":"Keys"},{"location":"client_tools/config_yml/#environment","text":"Additional environment variable assignments to be included in submissions. For example, you may want to upload and run a pre-render script. You can use this key to add the path to the script. environment : PATH : /path/to/my/scripts","title":"environment"},{"location":"client_tools/config_yml/#output_dir","text":"By default, files are downloaded to the directory that was specified on submission. Use this key to override that directory and download to the specified location. output_dir : /special/path/to/my/renders","title":"output_dir"},{"location":"client_tools/config_yml/#upload_paths","text":"A list of additional paths to be uploaded. Both files and directories are valid. upload_paths : - /path/to/my/scripts/prerender.py - /assets/not/detected/during/dependency/scan/","title":"upload_paths"},{"location":"client_tools/config_yml/#local_upload","text":"Specify whether uploads should run on the workstation where jobs are submitted. Set this key to False if you have a dedicated machine to run an uploader daemon. local_upload : False","title":"local_upload"},{"location":"client_tools/config_yml/#api_key_path","text":"Full path to the location of a file containing your API_KEY. This is optional if you are not running an uploader or downloader daemons. api_key_path : /path/to/my/conductor_api_key.json","title":"api_key_path"},{"location":"client_tools/config_yml/#location","text":"Tag your submissions with a location. This allows you to download only those tagged jobs while running the downloader daemon. location : london_studio","title":"location"},{"location":"client_tools/install/","text":"Install client tools \u00b6 To install the Conductor client tools, choose an installer from the list below. If you are working in a shared environment, it is recommended that you install manually in a shared location and set a few environment variables for your studio. Downloads \u00b6 For Maya and Nuke \u00b6 Release label Operating system Download link Stable Centos el7 installer conductor-v2.7.100-0.el7.x86_64.rpm Stable Windows 10 installer conductor-v2.7.100.exe Stable Mac installer conductor-v2.7.100.pkg Stable Manual install v2.7.100.tar.gz For Clarisse \u00b6 Release label Operating system Download link Clarisse beta Centos el7 installer conductor-v2.8.9-0.el7.x86_64.rpm Clarisse beta Windows 10 installer conductor-v2.8.9.exe Clarisse beta Mac installer conductor-v2.8.9.pkg Clarisse beta Manual install v2.8.9.tar.gz Others \u00b6 For all other versions, please visit the Github releases page To run an installer. \u00b6 Choose the appropriate link to download an installer for your operating system. Run the installer. Your system is set up and ready to submit jobs to Conductor. To install manually \u00b6 Copy the downloaded source directory to a location of your choice and set the following environment variables. The examples below use Bash, and Powershell for Windows. You should adjust for your chosen environment. Mac export CONDUCTOR_LOCATION = \"/path/to/conductor_client\" export CONDUCTOR_CONFIG = \" ${ HOME } /Library/Application Support/Conductor/config.yml\" # Python export PYTHONPATH = \" ${ PYTHONPATH } : ${ CONDUCTOR_LOCATION } : ${ CONDUCTOR_LOCATION } /installers/osx/python/lib/python2.7/site-packages\" # Maya export XBMLANGPATH = ${ CONDUCTOR_LOCATION } /conductor/resources: ${ XBMLANGPATH } export MAYA_SHELF_PATH = \" ${ CONDUCTOR_LOCATION } /maya_shelf\" # Nuke export NUKE_PATH = \" ${ NUKE_PATH } : ${ CONDUCTOR_LOCATION } /nuke_menu\" # Conductor command line utilities export PATH = \" ${ CONDUCTOR_LOCATION } /bin: $PATH \" Linux export CONDUCTOR_LOCATION = \"/path/to/conductor_client\" export CONDUCTOR_CONFIG = \" ${ HOME } /.conductor/config.yml\" # Python export PYTHONPATH = \" ${ PYTHONPATH } : ${ CONDUCTOR_LOCATION } : ${ CONDUCTOR_LOCATION } /python/lib/python2.7/site-packages\" # Maya export XBMLANGPATH = ${ CONDUCTOR_LOCATION } /conductor/resources: ${ XBMLANGPATH } export MAYA_SHELF_PATH = \" ${ CONDUCTOR_LOCATION } /maya_shelf\" # Nuke export NUKE_PATH = \" ${ NUKE_PATH } : ${ CONDUCTOR_LOCATION } /nuke_menu\" # Conductor command line utilities export PATH = \" ${ CONDUCTOR_LOCATION } /bin: $PATH \" Windows $Env:CONDUCTOR_LOCATION = \"C:\\path\\to\\conductor_client\" $Env:CONDUCTOR_CONFIG = \"$Env:HOME\\AppData\\Roaming\\Conductor Technologies\\Conductor\\config.yml\" # python $Env:PYTHONPATH += \";$Env:CONDUCTOR_LOCATION\" $Env:PYTHONPATH += \";$Env:CONDUCTOR_LOCATION\\installers\\windows\\python\\Lib\\site-packages\" # Maya $Env:XBMLANGPATH += \"$Env:CONDUCTOR_LOCATION\\conductor\\resources\" $Env:MAYA_SHELF_PATH += \"$Env:CONDUCTOR_LOCATION\\maya_shelf\" # Nuke $Env:NUKE_PATH = \"$Env:CONDUCTOR_LOCATION\\nuke_menu\" # Conductor command line utilities $Env:Path += \";$Env:CONDUCTOR_LOCATION/bin\" Troubleshooting \u00b6 If you are having trouble with the installation, here are some steps and suggestions to help you debug. Lorem ipsum, or lipsum as it is sometimes known, is dummy text used in laying out print. The passage is attributed to an unknown typesetter in the 15th century who. Cicero's De Finibus Bonorum et Malorum for use in a type specimen book.","title":"Install Client Tools"},{"location":"client_tools/install/#install-client-tools","text":"To install the Conductor client tools, choose an installer from the list below. If you are working in a shared environment, it is recommended that you install manually in a shared location and set a few environment variables for your studio.","title":"Install client tools"},{"location":"client_tools/install/#downloads","text":"","title":"Downloads"},{"location":"client_tools/install/#for-maya-and-nuke","text":"Release label Operating system Download link Stable Centos el7 installer conductor-v2.7.100-0.el7.x86_64.rpm Stable Windows 10 installer conductor-v2.7.100.exe Stable Mac installer conductor-v2.7.100.pkg Stable Manual install v2.7.100.tar.gz","title":"For Maya and Nuke"},{"location":"client_tools/install/#for-clarisse","text":"Release label Operating system Download link Clarisse beta Centos el7 installer conductor-v2.8.9-0.el7.x86_64.rpm Clarisse beta Windows 10 installer conductor-v2.8.9.exe Clarisse beta Mac installer conductor-v2.8.9.pkg Clarisse beta Manual install v2.8.9.tar.gz","title":"For Clarisse"},{"location":"client_tools/install/#others","text":"For all other versions, please visit the Github releases page","title":"Others"},{"location":"client_tools/install/#to-run-an-installer","text":"Choose the appropriate link to download an installer for your operating system. Run the installer. Your system is set up and ready to submit jobs to Conductor.","title":"To run an installer."},{"location":"client_tools/install/#to-install-manually","text":"Copy the downloaded source directory to a location of your choice and set the following environment variables. The examples below use Bash, and Powershell for Windows. You should adjust for your chosen environment. Mac export CONDUCTOR_LOCATION = \"/path/to/conductor_client\" export CONDUCTOR_CONFIG = \" ${ HOME } /Library/Application Support/Conductor/config.yml\" # Python export PYTHONPATH = \" ${ PYTHONPATH } : ${ CONDUCTOR_LOCATION } : ${ CONDUCTOR_LOCATION } /installers/osx/python/lib/python2.7/site-packages\" # Maya export XBMLANGPATH = ${ CONDUCTOR_LOCATION } /conductor/resources: ${ XBMLANGPATH } export MAYA_SHELF_PATH = \" ${ CONDUCTOR_LOCATION } /maya_shelf\" # Nuke export NUKE_PATH = \" ${ NUKE_PATH } : ${ CONDUCTOR_LOCATION } /nuke_menu\" # Conductor command line utilities export PATH = \" ${ CONDUCTOR_LOCATION } /bin: $PATH \" Linux export CONDUCTOR_LOCATION = \"/path/to/conductor_client\" export CONDUCTOR_CONFIG = \" ${ HOME } /.conductor/config.yml\" # Python export PYTHONPATH = \" ${ PYTHONPATH } : ${ CONDUCTOR_LOCATION } : ${ CONDUCTOR_LOCATION } /python/lib/python2.7/site-packages\" # Maya export XBMLANGPATH = ${ CONDUCTOR_LOCATION } /conductor/resources: ${ XBMLANGPATH } export MAYA_SHELF_PATH = \" ${ CONDUCTOR_LOCATION } /maya_shelf\" # Nuke export NUKE_PATH = \" ${ NUKE_PATH } : ${ CONDUCTOR_LOCATION } /nuke_menu\" # Conductor command line utilities export PATH = \" ${ CONDUCTOR_LOCATION } /bin: $PATH \" Windows $Env:CONDUCTOR_LOCATION = \"C:\\path\\to\\conductor_client\" $Env:CONDUCTOR_CONFIG = \"$Env:HOME\\AppData\\Roaming\\Conductor Technologies\\Conductor\\config.yml\" # python $Env:PYTHONPATH += \";$Env:CONDUCTOR_LOCATION\" $Env:PYTHONPATH += \";$Env:CONDUCTOR_LOCATION\\installers\\windows\\python\\Lib\\site-packages\" # Maya $Env:XBMLANGPATH += \"$Env:CONDUCTOR_LOCATION\\conductor\\resources\" $Env:MAYA_SHELF_PATH += \"$Env:CONDUCTOR_LOCATION\\maya_shelf\" # Nuke $Env:NUKE_PATH = \"$Env:CONDUCTOR_LOCATION\\nuke_menu\" # Conductor command line utilities $Env:Path += \";$Env:CONDUCTOR_LOCATION/bin\"","title":"To install manually"},{"location":"client_tools/install/#troubleshooting","text":"If you are having trouble with the installation, here are some steps and suggestions to help you debug. Lorem ipsum, or lipsum as it is sometimes known, is dummy text used in laying out print. The passage is attributed to an unknown typesetter in the 15th century who. Cicero's De Finibus Bonorum et Malorum for use in a type specimen book.","title":"Troubleshooting"},{"location":"client_tools/plugins/clarisse/","text":"Clarisse submitter. \u00b6 Introduction \u00b6 The Conductor submitter for Clarisse allows you to ship renders to Conductor's cloud from a familiar interface within Clarisse. It's implemented as a custom class that lives inside the project. The class name is ConductorJob. You may configure many ConductorJobs in a single project in order to try out different cloud parameters. A single job may also be set up to render many images, such as multiple VR cameras. Any properties you set on a ConductorJob will be stored inside the project when you save so you can be confident that subsequent renders of the same scene will behave the same. Installation \u00b6 If you haven't already done so, install Conductor client tools . Register the plugin \u00b6 To register the submitter, set the path to the provided script in the Startup Script section of the preferences panel. It will take effect the next time you start Clarisse. $CONDUCTOR_LOCATION /conductor/clarisse/startup.py Note To avoid a restart, enter the following in the script editor: from conductor.clarisse import startup Once the plugin is registered, you should see ConductorJob in the Create menu, and in the New menu when you right click over a browser. If not, refer to installation troubleshooting or submit a ticket to Conductor support . Quick start \u00b6 To create a submission to Conductor: \u00b6 Open a scene containing one or more images to be rendered. Select the project context. In the right mouse menu, go to New > ConductorJob . You'll now see a ConductorJob item in the attribute editor. Note You can hover over any attribute name to get a detailed description of its purpose and behavior. Set a title for your job. This will show up on the Conductor dashboard. Click Add in the Images section to choose some images to be rendered. If you haven't done so already, turn on Render To Disk for each image and set a filename in the Save As attribute. You'll notice the project is - not set - and the pulldown menu is empty. This is because the submitter has not yet been in contact with your account at Conductor. Press the Refresh button at the top of the attribute editor and if prompted, sign in to Conductor. Choose a project from the Project drop-down menu. In the Frames section, turn on Use Custom Frames and enter 1-10 in the Custom Frames field. Set Chunk Size to 2. Turn on Use Scout Frames and enter 3,8 in Scout Frames field. You'll notice the Frames Info attribute has updated to let you know which frames will be submitted, and how many will be scouted first. If you know the machine specification needed for your images, choose it in the Instance Type drop-down menu. Check that your version of Clarisse appears in the Packages attribute. If it hasn't been detected, you'll need to open the Choose Packages panel and choose a suitable version. You are now ready to submit your render using either the Submit or Preview buttons, which you'll find at the top of the attribute editor. You are encouraged to use the Preview button, which will allow you to first check the parameters that will be submitted. If everything looks good, press the Submit button, and then head over to your Conductor dashboard to check on the job's progress. Reference \u00b6 In this section you'll find a complete discussion of attributes, variables and other functionality. Attributes \u00b6 title \u00b6 The title that appears in the Conductor dashboard. You may use Clarisse variables and some Conductor variables in an expression to construct the title. If for example, you want the title to contain the filename, the item name, and the frame range, then enter the following expression. \"$CT_PDIR +\" \"+ $CT_JOB +\" \"+ $CT_SEQUENCE images \u00b6 Images to be rendered. Images must have the Render to Disk attribute set and their Save As field must contain a filename. You may use the eye buttons to disable one or more images. conductor_project_name \u00b6 The Conductor project. The dropdown menu is populated or updated when the submitter connects to your Conductor account. If the menu contains only the - not set - option, then press the refresh button to connect. Note If the list of projects in your account changed since the last time you opened the Clarisse project, you may find it is set incorrectly when it connects. use_custom_frames \u00b6 Activate a text field to enter a custom frame list. When set, the frame ranges on connected image items will be ignored and the custom frames will be used for all. If you leave use_custom_frames off, then each image may specify it's own range and they may be different from each other. By default, the render command generated for each task renders all images together and calculates the correct frames to render for each image within the chunk. custom_frames \u00b6 The set of frames to render when use_custom_frames is on. To specify te set of frames enter a comma-separated list of arithmetic progressions. In most cases, this will be s simple range. 1001-1200 However, any set of frames may be specified efficiently in this way. 1,7,10-20,30-60x3,1001 Negative frame numbers are not valid. chunk_size \u00b6 A chunk is the set of frames handled by one task. If your renders are fairly fast, it may make sense to render may frames per task, because the time it takes to spin up instances and sync can be significant by comparison. best_chunk_size \u00b6 A convenience function that will try to distribute frames more evenly among chunks. It adjusts chunk_size while keeping the number of chunks unchanged. A contrived example. You want to render 100 frames and you set the chunk size to 33. This generates 4 chunks of lengths, 33, 33, 33, and 1. If you press best_chunk_size , chunk_size becomes 25. You still have 4 chunks. use_scout_frames \u00b6 Activates a set of frames to be rendered first. This allows you to check a subsample of frames before committing to the full render. scout_frames \u00b6 Scout-frames to render. When the submission reaches Conductor, only those tasks containing the specified scout frames are started. Other tasks are set to a holding state. Note If chunk_size is greater than one, then you may find extra frames are rendered that were not listed as scout frames. As the smallest unit of execution is a task, there is no way to specify that part of a task should be started and another part held. preemptible \u00b6 Preemptible instances are less expensive to run than non-preemptible. The drawback is that they may be stopped at any time by the cloud provider. The probability of an instance being preempted rises with the duration of the task. Conductor does not support checkpointing, so if a task is preempted it is started from scratch on another instance. It is possible to change the preemptible setting in the dashboard for your account. instance_type \u00b6 Specify the hardware configuration used to run your tasks. Higher specification instances are potentially faster and able to handle heavier scenes. You are encouraged to run tests to find the most cost-efficient combination that meets your deadline. retries \u00b6 Set the number of times to retry a failed task before marking it failed. dependency_scan_policy \u00b6 Specify how to find files that the project depends on. Your project is likely to contain references to external textures and geometry caches. These files all need to be uploaded. The dependency-scan searches for these files at the time you generate a preview or submit a job. There are 3 options. No Scan. No scan will be performed. This may be useful if the scanning process is slow for your project. You can instead choose to cache the list of dependencies. See manage_extra_uploads . If you choose this method, you should be aware when new textures or other dependencies are added to your project, and add them to the upload list manually. Smart Sequence. When set, an attempt is made to identify for upload, only those files needed by the frames being rendered. Filenames are searched for two patterns that indicate a time-varying component: #### and $4F . If any number of hashes are found in a filename, then the list of files to upload is calculated based on the frames set in the ConductorJob, and the sequence attributes associated with the filename. Likewise, if $F variables are found, the list of files will reflect the frames as specified in the ConductorJob. However, expressions such as $F * 2 are not resolved. Glob. Find all files that exist on disk that could match either of the two time-varying patterns. If for example, your shot is 50 frames, but you have 100 images on disk, then a glob scan will find and uploads all those images even though half of them are not used. Note Contexts that reference external Clarisse projects are ignored during the dependency scan. They are localized in the render package and are therefore not required for rendering. Example Suppose you have a sequence of 1000 background images on disk. Your shot is 20 frames long and you've set the sequence attributes on the texture map to start 100 frames in. (-100 frame offset). The smart scan option will find frames from 0101 to 0120. The Glob option finds any files that match a hash pattern. If you have saved all required files in the cached upload list, you can set the policy to No Scan. local_upload \u00b6 Uploads files from your workstation, as opposed to using an upload daemon. force_upload \u00b6 Forces files to be uploaded, even if they already exist at Conductor. upload_only \u00b6 Uploads files but does not start any tasks. manage_extra_uploads \u00b6 Opens a panel to browse or scan for files to upload. If any files are not found by the dependency scan at submission time, they may be added here. extra_uploads \u00b6 Files to uploaded in addition to any files found by dependency scanning. choose_packages \u00b6 Opens the package chooser panel. packages \u00b6 Packages made available to the remote compute instances. manage_extra_environment \u00b6 Opens a panel for making modifications to the remote environment. extra_environment \u00b6 Extra environment encoded as a JSON string. task_template \u00b6 Specifies a template for the command that will be run on remote instances. See the Conductor documentation site for a detailed discussion. notify \u00b6 Indicates that notifications will be sent by email on job completion. email_addresses \u00b6 A comma-delimited list of emails addresses to notify on job completion. show_tracebacks \u00b6 Show a full stacktrace for software errors in the submitter. conductor_log_level \u00b6 Set the log level for Conductor's library logging. Actions \u00b6 Extra uploads window \u00b6 Package chooser \u00b6 Extra environment window \u00b6 Conductor Variables \u00b6 The ConductorJob scripted class is designed to be flexible and powerful. Commands that are executed on Conductor's cloud machines are fully configurable from within the UI. In order to achieve this level of control, a set of variables are available. These are found in Clarisse's Variables panel. In most cases, you don't need them other than to set the job title. If you choose to use them you should understand how they work. All the Conductor variables are prefixed with CT_ and are created when the ConductorJob is first registered with Clarisse. They are intended for use only in ConductorJob items, and their values are set at the time you create a submission or preview. They cannot be relied upon outside this context, and the value displayed in the Variables panel is only the last value that was set. Conductor variables that hold paths are formatted to be compatible with Linux render instances. They are enclosed in double quotes, and on Windows, the drive letters are stripped away. Conductor variables exist at 3 different scopes: \u00b6 Global. The same value for all job items. Example CT_TMP_DIR . Job. A different vaue for each job. Example CT_SEQUENCE Task. A different vaue for each generated task. . Example CT_CHUNKS Below is the full list of Conductor variables. Variable name Example value Scope CT_SEQLENGTH 10 Job CT_SEQUENCE 1-10 Job CT_SEQUENCEMIN 1 Job CT_SEQUENCEMAX 10 Job CT_CORES 2 Job CT_FLAVOR standard Job CT_INSTANCE 2 core, 7.50GB Mem Job CT_PREEMPTIBLE preemptible Job CT_RETRIES 3 Job CT_JOB conductor_job_item_name Job CT_SOURCES project://scene/image1 project://scene/image2 Job CT_SCOUT 3-8x5 Job CT_CHUNKSIZE 2 Job CT_CHUNKCOUNT 5 Job CT_SCOUTCOUNT 2 Job CT_TIMESTAMP 2019_05_07_01_12_46 Job CT_RENDER_PACKAGE \"/path/to/project/shot.render\" Global CT_PROJECT dpool Job CT_CHUNKS 9:10 9:10 Task CT_CHUNKLENGTH 2 Task CT_CHUNKSTART 9 Task CT_CHUNKEND 10 Task CT_DIRECTORIES \"/path/to/renders/layerA\" \"/path/to/renders/layerB\" Job CT_PDIR /path/to/project Global CT_TEMP_DIR \"/path/to/temp/directory\" Global","title":"Clarisse"},{"location":"client_tools/plugins/clarisse/#clarisse-submitter","text":"","title":"Clarisse submitter."},{"location":"client_tools/plugins/clarisse/#introduction","text":"The Conductor submitter for Clarisse allows you to ship renders to Conductor's cloud from a familiar interface within Clarisse. It's implemented as a custom class that lives inside the project. The class name is ConductorJob. You may configure many ConductorJobs in a single project in order to try out different cloud parameters. A single job may also be set up to render many images, such as multiple VR cameras. Any properties you set on a ConductorJob will be stored inside the project when you save so you can be confident that subsequent renders of the same scene will behave the same.","title":"Introduction"},{"location":"client_tools/plugins/clarisse/#installation","text":"If you haven't already done so, install Conductor client tools .","title":"Installation"},{"location":"client_tools/plugins/clarisse/#register-the-plugin","text":"To register the submitter, set the path to the provided script in the Startup Script section of the preferences panel. It will take effect the next time you start Clarisse. $CONDUCTOR_LOCATION /conductor/clarisse/startup.py Note To avoid a restart, enter the following in the script editor: from conductor.clarisse import startup Once the plugin is registered, you should see ConductorJob in the Create menu, and in the New menu when you right click over a browser. If not, refer to installation troubleshooting or submit a ticket to Conductor support .","title":"Register the plugin"},{"location":"client_tools/plugins/clarisse/#quick-start","text":"","title":"Quick start"},{"location":"client_tools/plugins/clarisse/#to-create-a-submission-to-conductor","text":"Open a scene containing one or more images to be rendered. Select the project context. In the right mouse menu, go to New > ConductorJob . You'll now see a ConductorJob item in the attribute editor. Note You can hover over any attribute name to get a detailed description of its purpose and behavior. Set a title for your job. This will show up on the Conductor dashboard. Click Add in the Images section to choose some images to be rendered. If you haven't done so already, turn on Render To Disk for each image and set a filename in the Save As attribute. You'll notice the project is - not set - and the pulldown menu is empty. This is because the submitter has not yet been in contact with your account at Conductor. Press the Refresh button at the top of the attribute editor and if prompted, sign in to Conductor. Choose a project from the Project drop-down menu. In the Frames section, turn on Use Custom Frames and enter 1-10 in the Custom Frames field. Set Chunk Size to 2. Turn on Use Scout Frames and enter 3,8 in Scout Frames field. You'll notice the Frames Info attribute has updated to let you know which frames will be submitted, and how many will be scouted first. If you know the machine specification needed for your images, choose it in the Instance Type drop-down menu. Check that your version of Clarisse appears in the Packages attribute. If it hasn't been detected, you'll need to open the Choose Packages panel and choose a suitable version. You are now ready to submit your render using either the Submit or Preview buttons, which you'll find at the top of the attribute editor. You are encouraged to use the Preview button, which will allow you to first check the parameters that will be submitted. If everything looks good, press the Submit button, and then head over to your Conductor dashboard to check on the job's progress.","title":"To create a submission to Conductor:"},{"location":"client_tools/plugins/clarisse/#reference","text":"In this section you'll find a complete discussion of attributes, variables and other functionality.","title":"Reference"},{"location":"client_tools/plugins/clarisse/#attributes","text":"","title":"Attributes"},{"location":"client_tools/plugins/clarisse/#title","text":"The title that appears in the Conductor dashboard. You may use Clarisse variables and some Conductor variables in an expression to construct the title. If for example, you want the title to contain the filename, the item name, and the frame range, then enter the following expression. \"$CT_PDIR +\" \"+ $CT_JOB +\" \"+ $CT_SEQUENCE","title":"title"},{"location":"client_tools/plugins/clarisse/#images","text":"Images to be rendered. Images must have the Render to Disk attribute set and their Save As field must contain a filename. You may use the eye buttons to disable one or more images.","title":"images"},{"location":"client_tools/plugins/clarisse/#conductor_project_name","text":"The Conductor project. The dropdown menu is populated or updated when the submitter connects to your Conductor account. If the menu contains only the - not set - option, then press the refresh button to connect. Note If the list of projects in your account changed since the last time you opened the Clarisse project, you may find it is set incorrectly when it connects.","title":"conductor_project_name"},{"location":"client_tools/plugins/clarisse/#use_custom_frames","text":"Activate a text field to enter a custom frame list. When set, the frame ranges on connected image items will be ignored and the custom frames will be used for all. If you leave use_custom_frames off, then each image may specify it's own range and they may be different from each other. By default, the render command generated for each task renders all images together and calculates the correct frames to render for each image within the chunk.","title":"use_custom_frames"},{"location":"client_tools/plugins/clarisse/#custom_frames","text":"The set of frames to render when use_custom_frames is on. To specify te set of frames enter a comma-separated list of arithmetic progressions. In most cases, this will be s simple range. 1001-1200 However, any set of frames may be specified efficiently in this way. 1,7,10-20,30-60x3,1001 Negative frame numbers are not valid.","title":"custom_frames"},{"location":"client_tools/plugins/clarisse/#chunk_size","text":"A chunk is the set of frames handled by one task. If your renders are fairly fast, it may make sense to render may frames per task, because the time it takes to spin up instances and sync can be significant by comparison.","title":"chunk_size"},{"location":"client_tools/plugins/clarisse/#best_chunk_size","text":"A convenience function that will try to distribute frames more evenly among chunks. It adjusts chunk_size while keeping the number of chunks unchanged. A contrived example. You want to render 100 frames and you set the chunk size to 33. This generates 4 chunks of lengths, 33, 33, 33, and 1. If you press best_chunk_size , chunk_size becomes 25. You still have 4 chunks.","title":"best_chunk_size"},{"location":"client_tools/plugins/clarisse/#use_scout_frames","text":"Activates a set of frames to be rendered first. This allows you to check a subsample of frames before committing to the full render.","title":"use_scout_frames"},{"location":"client_tools/plugins/clarisse/#scout_frames","text":"Scout-frames to render. When the submission reaches Conductor, only those tasks containing the specified scout frames are started. Other tasks are set to a holding state. Note If chunk_size is greater than one, then you may find extra frames are rendered that were not listed as scout frames. As the smallest unit of execution is a task, there is no way to specify that part of a task should be started and another part held.","title":"scout_frames"},{"location":"client_tools/plugins/clarisse/#preemptible","text":"Preemptible instances are less expensive to run than non-preemptible. The drawback is that they may be stopped at any time by the cloud provider. The probability of an instance being preempted rises with the duration of the task. Conductor does not support checkpointing, so if a task is preempted it is started from scratch on another instance. It is possible to change the preemptible setting in the dashboard for your account.","title":"preemptible"},{"location":"client_tools/plugins/clarisse/#instance_type","text":"Specify the hardware configuration used to run your tasks. Higher specification instances are potentially faster and able to handle heavier scenes. You are encouraged to run tests to find the most cost-efficient combination that meets your deadline.","title":"instance_type"},{"location":"client_tools/plugins/clarisse/#retries","text":"Set the number of times to retry a failed task before marking it failed.","title":"retries"},{"location":"client_tools/plugins/clarisse/#dependency_scan_policy","text":"Specify how to find files that the project depends on. Your project is likely to contain references to external textures and geometry caches. These files all need to be uploaded. The dependency-scan searches for these files at the time you generate a preview or submit a job. There are 3 options. No Scan. No scan will be performed. This may be useful if the scanning process is slow for your project. You can instead choose to cache the list of dependencies. See manage_extra_uploads . If you choose this method, you should be aware when new textures or other dependencies are added to your project, and add them to the upload list manually. Smart Sequence. When set, an attempt is made to identify for upload, only those files needed by the frames being rendered. Filenames are searched for two patterns that indicate a time-varying component: #### and $4F . If any number of hashes are found in a filename, then the list of files to upload is calculated based on the frames set in the ConductorJob, and the sequence attributes associated with the filename. Likewise, if $F variables are found, the list of files will reflect the frames as specified in the ConductorJob. However, expressions such as $F * 2 are not resolved. Glob. Find all files that exist on disk that could match either of the two time-varying patterns. If for example, your shot is 50 frames, but you have 100 images on disk, then a glob scan will find and uploads all those images even though half of them are not used. Note Contexts that reference external Clarisse projects are ignored during the dependency scan. They are localized in the render package and are therefore not required for rendering. Example Suppose you have a sequence of 1000 background images on disk. Your shot is 20 frames long and you've set the sequence attributes on the texture map to start 100 frames in. (-100 frame offset). The smart scan option will find frames from 0101 to 0120. The Glob option finds any files that match a hash pattern. If you have saved all required files in the cached upload list, you can set the policy to No Scan.","title":"dependency_scan_policy"},{"location":"client_tools/plugins/clarisse/#local_upload","text":"Uploads files from your workstation, as opposed to using an upload daemon.","title":"local_upload"},{"location":"client_tools/plugins/clarisse/#force_upload","text":"Forces files to be uploaded, even if they already exist at Conductor.","title":"force_upload"},{"location":"client_tools/plugins/clarisse/#upload_only","text":"Uploads files but does not start any tasks.","title":"upload_only"},{"location":"client_tools/plugins/clarisse/#manage_extra_uploads","text":"Opens a panel to browse or scan for files to upload. If any files are not found by the dependency scan at submission time, they may be added here.","title":"manage_extra_uploads"},{"location":"client_tools/plugins/clarisse/#extra_uploads","text":"Files to uploaded in addition to any files found by dependency scanning.","title":"extra_uploads"},{"location":"client_tools/plugins/clarisse/#choose_packages","text":"Opens the package chooser panel.","title":"choose_packages"},{"location":"client_tools/plugins/clarisse/#packages","text":"Packages made available to the remote compute instances.","title":"packages"},{"location":"client_tools/plugins/clarisse/#manage_extra_environment","text":"Opens a panel for making modifications to the remote environment.","title":"manage_extra_environment"},{"location":"client_tools/plugins/clarisse/#extra_environment","text":"Extra environment encoded as a JSON string.","title":"extra_environment"},{"location":"client_tools/plugins/clarisse/#task_template","text":"Specifies a template for the command that will be run on remote instances. See the Conductor documentation site for a detailed discussion.","title":"task_template"},{"location":"client_tools/plugins/clarisse/#notify","text":"Indicates that notifications will be sent by email on job completion.","title":"notify"},{"location":"client_tools/plugins/clarisse/#email_addresses","text":"A comma-delimited list of emails addresses to notify on job completion.","title":"email_addresses"},{"location":"client_tools/plugins/clarisse/#show_tracebacks","text":"Show a full stacktrace for software errors in the submitter.","title":"show_tracebacks"},{"location":"client_tools/plugins/clarisse/#conductor_log_level","text":"Set the log level for Conductor's library logging.","title":"conductor_log_level"},{"location":"client_tools/plugins/clarisse/#actions","text":"","title":"Actions"},{"location":"client_tools/plugins/clarisse/#extra-uploads-window","text":"","title":"Extra uploads window"},{"location":"client_tools/plugins/clarisse/#package-chooser","text":"","title":"Package chooser"},{"location":"client_tools/plugins/clarisse/#extra-environment-window","text":"","title":"Extra environment window"},{"location":"client_tools/plugins/clarisse/#conductor-variables","text":"The ConductorJob scripted class is designed to be flexible and powerful. Commands that are executed on Conductor's cloud machines are fully configurable from within the UI. In order to achieve this level of control, a set of variables are available. These are found in Clarisse's Variables panel. In most cases, you don't need them other than to set the job title. If you choose to use them you should understand how they work. All the Conductor variables are prefixed with CT_ and are created when the ConductorJob is first registered with Clarisse. They are intended for use only in ConductorJob items, and their values are set at the time you create a submission or preview. They cannot be relied upon outside this context, and the value displayed in the Variables panel is only the last value that was set. Conductor variables that hold paths are formatted to be compatible with Linux render instances. They are enclosed in double quotes, and on Windows, the drive letters are stripped away.","title":"Conductor Variables"},{"location":"client_tools/plugins/clarisse/#conductor-variables-exist-at-3-different-scopes","text":"Global. The same value for all job items. Example CT_TMP_DIR . Job. A different vaue for each job. Example CT_SEQUENCE Task. A different vaue for each generated task. . Example CT_CHUNKS Below is the full list of Conductor variables. Variable name Example value Scope CT_SEQLENGTH 10 Job CT_SEQUENCE 1-10 Job CT_SEQUENCEMIN 1 Job CT_SEQUENCEMAX 10 Job CT_CORES 2 Job CT_FLAVOR standard Job CT_INSTANCE 2 core, 7.50GB Mem Job CT_PREEMPTIBLE preemptible Job CT_RETRIES 3 Job CT_JOB conductor_job_item_name Job CT_SOURCES project://scene/image1 project://scene/image2 Job CT_SCOUT 3-8x5 Job CT_CHUNKSIZE 2 Job CT_CHUNKCOUNT 5 Job CT_SCOUTCOUNT 2 Job CT_TIMESTAMP 2019_05_07_01_12_46 Job CT_RENDER_PACKAGE \"/path/to/project/shot.render\" Global CT_PROJECT dpool Job CT_CHUNKS 9:10 9:10 Task CT_CHUNKLENGTH 2 Task CT_CHUNKSTART 9 Task CT_CHUNKEND 10 Task CT_DIRECTORIES \"/path/to/renders/layerA\" \"/path/to/renders/layerB\" Job CT_PDIR /path/to/project Global CT_TEMP_DIR \"/path/to/temp/directory\" Global","title":"Conductor variables exist at 3 different scopes:"},{"location":"client_tools/plugins/maya/","text":"Maya submitter. \u00b6 Introduction \u00b6 The Conductor submitter for Maya allows you to ship renders to Conductor's cloud from a familiar interface within Maya.... WIP","title":"Maya"},{"location":"client_tools/plugins/maya/#maya-submitter","text":"","title":"Maya submitter."},{"location":"client_tools/plugins/maya/#introduction","text":"The Conductor submitter for Maya allows you to ship renders to Conductor's cloud from a familiar interface within Maya.... WIP","title":"Introduction"},{"location":"client_tools/plugins/nuke/","text":"Nuke submitter. \u00b6 Introduction \u00b6 The Conductor submitter for Nuke allows you to ship renders to Conductor's cloud from a familiar interface within Nuke.... WIP","title":"Nuke"},{"location":"client_tools/plugins/nuke/#nuke-submitter","text":"","title":"Nuke submitter."},{"location":"client_tools/plugins/nuke/#introduction","text":"The Conductor submitter for Nuke allows you to ship renders to Conductor's cloud from a familiar interface within Nuke.... WIP","title":"Introduction"},{"location":"knowledgebase/instance_types/","text":"Instance type table \u00b6","title":"Instance Types"},{"location":"knowledgebase/instance_types/#instance-type-table","text":"","title":"Instance type table"},{"location":"knowledgebase/troubleshooting/","text":"Troubleshooting \u00b6","title":"Troubleshooting"},{"location":"knowledgebase/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"web_dashboard/jobs_view/","text":"Jobs view \u00b6 Introduction \u00b6","title":"Jobs View"},{"location":"web_dashboard/jobs_view/#jobs-view","text":"","title":"Jobs view"},{"location":"web_dashboard/jobs_view/#introduction","text":"","title":"Introduction"}]}